{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Pre-process the Data\n",
    "Complete some basic text preprocessing steps and create some different features based on the wikipedia training data and other data sets provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "from feature_extractor import feature_mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the training and testing data\n",
    "train = pd.read_csv(\"assets/WikiLarge_Train.csv\")\n",
    "test = pd.read_csv(\"assets/WikiLarge_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  label\n",
       "0  There is manuscript evidence that Austen conti...      1\n",
       "1  In a remarkable comparative analysis , Mandaea...      1\n",
       "2  Before Persephone was released to Hermes , who...      1\n",
       "3  Cogeneration plants are commonly found in dist...      1\n",
       "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the data frames\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id original_text  label\n",
       "0   0         -2011    NaN\n",
       "1   1         -2011    NaN\n",
       "2   2         -2000    NaN\n",
       "3   3         -1997    NaN\n",
       "4   4         1.636    NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineer Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to preprocess the text, we first tokenized each sentence. We also created another column with the words tokenized, lowercased, and lemmatized. We did not remove stop words at this point because during our testing we found we got better results if we left the stop words in the sentences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tokens\n",
    "train = feature_mods.tokens(train)\n",
    "test = feature_mods.tokens(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416768/416768 [09:01<00:00, 769.57it/s] \n",
      "100%|██████████| 119092/119092 [01:44<00:00, 1142.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the token_lemmas POSSIBLY REMOVE\n",
    "train = feature_mods.token_lemmas(train)\n",
    "test = feature_mods.token_lemmas(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also created a features which contained the count and ratio of \"hard words\" in each sentence. Hard words were determined by if they were not included in the concreteness lemmas, dale chall words, or lemmas that people under the age of 12 knew in the AoA data. We used the token_lemmas column in our data frame to calculate this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hard word ratio \n",
    "train = feature_mods.get_hard_word_ratio(train, 12)\n",
    "test = feature_mods.get_hard_word_ratio(test, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarly we created columns which contained the count and ratio of \"advanced words\". These are words that people over the age of 8 know as well as words that less than 92% of people knew. We used the regular tokens to calculate this. Even though the AoA and concreteness data are lowercased and the concreteness data includes lemmas we found we got better results using the regular tokens to create this feature.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the advanced words, count and the ratio of advanced words out of all the tokens\n",
    "train = feature_mods.add_difficulty_columns(train, 8, .92)\n",
    "test = feature_mods.add_difficulty_columns(test, 8, .92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also retrieved the parts-of-speech for all words in the original text. We found through our testing, data exploration, and research that different combinations of parts-of-speech in a sentence can make sentences more or less easy to comprehend**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the part of speech tags for the original text\n",
    "train = feature_mods.pos_tokens(train)\n",
    "test = feature_mods.pos_tokens(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Length is an obvious choice of feature given the notion that more complex sentences are likely to be relatively longer. In order to account for length, we merely count the number of tokens.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the number of words in a sentence\n",
    "train = feature_mods.length(train)\n",
    "test = feature_mods.length(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given the likelihood that more difficult vocabulary contains more characters on average, we computed the average length of tokens within a given sentence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the average length of a word in a sentence\n",
    "train = feature_mods.average_word_length(train)\n",
    "test = feature_mods.average_word_length(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If there are more named entities in a given sentence this could indicate a sentence is harder to understand since there are more nouns the reader is forced to remember.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with named entities, count and the ratio of number of named entities in the original text\n",
    "train = feature_mods.named_entity_counter(train)\n",
    "test = feature_mods.named_entity_counter(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More punctuation could indicate more complex sentence structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for the count and ratio of punctuation to regular characters in the original text\n",
    "train = feature_mods.add_punctuation(train)\n",
    "test = feature_mods.add_punctuation(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given that the relative frequency of parts of speech might provide information about the difficulty of a sentence, we created a column for each part of speech indicating the ratio of tokens in the sentence that belong to each grammatical category.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:16<00:00,  2.11it/s]\n",
      "100%|██████████| 35/35 [00:04<00:00,  8.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Add a column with the ratio of each part of speech in the original text\n",
    "train = feature_mods.add_pos_count_columns(train)\n",
    "test = feature_mods.add_pos_count_columns(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to only the columns needed for the model\n",
    "columns = ['original_text', 'label', 'tokens', 'token_lemmas', 'length', 'advanced_word_count', 'advanced_words_ratio','hard_word_count', \n",
    "           'hard_word_ratio', 'named_entity_count', 'named_entity_ratio', 'punctuation_score', 'punctuation_ratio', 'CC', \n",
    "           'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', \n",
    "           'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', \n",
    "           'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', 'avg_word_length']\n",
    "train = train[columns]\n",
    "test = test[columns+['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string version of tokens and token_lemmas columns\n",
    "train['token_string'] = train['tokens'].apply(lambda x: ' '.join(x))\n",
    "train['token_lemmas_string'] = train['token_lemmas'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word embeddings feature representation\n",
    "train_word_embeddings = feature_mods.create_embeddings(train)\n",
    "test_word_embeddings = feature_mods.create_embeddings(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('assets/wiki_train_preprocessed5.csv', index = False)\n",
    "test.to_csv('assets/wiki_test_preprocessed5.csv', index = False)\n",
    "\n",
    "train_word_embeddings.to_csv('assets/embeddings_train.csv', index = False)\n",
    "test_word_embeddings.to_csv('assets/embeddings_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
